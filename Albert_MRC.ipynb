{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Albert_MRC.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP6yJsbgj3fyCU8QgcE8c2n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rohitdwivedi16111998/rohitdwivedi/blob/master/Albert_MRC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4Wss740VOBV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "254d5a57-edf6-4d7e-b37e-0069755981a8"
      },
      "source": [
        "!git clone https://github.com/huggingface/transformers \\\n",
        "&& cd transformers \\\n",
        "&& git checkout a3085020ed0d81d4903c50967687192e3101e770 "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'transformers'...\n",
            "remote: Enumerating objects: 169, done.\u001b[K\n",
            "remote: Counting objects:   0% (1/169)\u001b[K\rremote: Counting objects:   1% (2/169)\u001b[K\rremote: Counting objects:   2% (4/169)\u001b[K\rremote: Counting objects:   3% (6/169)\u001b[K\rremote: Counting objects:   4% (7/169)\u001b[K\rremote: Counting objects:   5% (9/169)\u001b[K\rremote: Counting objects:   6% (11/169)\u001b[K\rremote: Counting objects:   7% (12/169)\u001b[K\rremote: Counting objects:   8% (14/169)\u001b[K\rremote: Counting objects:   9% (16/169)\u001b[K\rremote: Counting objects:  10% (17/169)\u001b[K\rremote: Counting objects:  11% (19/169)\u001b[K\rremote: Counting objects:  12% (21/169)\u001b[K\rremote: Counting objects:  13% (22/169)\u001b[K\rremote: Counting objects:  14% (24/169)\u001b[K\rremote: Counting objects:  15% (26/169)\u001b[K\rremote: Counting objects:  16% (28/169)\u001b[K\rremote: Counting objects:  17% (29/169)\u001b[K\rremote: Counting objects:  18% (31/169)\u001b[K\rremote: Counting objects:  19% (33/169)\u001b[K\rremote: Counting objects:  20% (34/169)\u001b[K\rremote: Counting objects:  21% (36/169)\u001b[K\rremote: Counting objects:  22% (38/169)\u001b[K\rremote: Counting objects:  23% (39/169)\u001b[K\rremote: Counting objects:  24% (41/169)\u001b[K\rremote: Counting objects:  25% (43/169)\u001b[K\rremote: Counting objects:  26% (44/169)\u001b[K\rremote: Counting objects:  27% (46/169)\u001b[K\rremote: Counting objects:  28% (48/169)\u001b[K\rremote: Counting objects:  29% (50/169)\u001b[K\rremote: Counting objects:  30% (51/169)\u001b[K\rremote: Counting objects:  31% (53/169)\u001b[K\rremote: Counting objects:  32% (55/169)\u001b[K\rremote: Counting objects:  33% (56/169)\u001b[K\rremote: Counting objects:  34% (58/169)\u001b[K\rremote: Counting objects:  35% (60/169)\u001b[K\rremote: Counting objects:  36% (61/169)\u001b[K\rremote: Counting objects:  37% (63/169)\u001b[K\rremote: Counting objects:  38% (65/169)\u001b[K\rremote: Counting objects:  39% (66/169)\u001b[K\rremote: Counting objects:  40% (68/169)\u001b[K\rremote: Counting objects:  41% (70/169)\u001b[K\rremote: Counting objects:  42% (71/169)\u001b[K\rremote: Counting objects:  43% (73/169)\u001b[K\rremote: Counting objects:  44% (75/169)\u001b[K\rremote: Counting objects:  45% (77/169)\u001b[K\rremote: Counting objects:  46% (78/169)\u001b[K\rremote: Counting objects:  47% (80/169)\u001b[K\rremote: Counting objects:  48% (82/169)\u001b[K\rremote: Counting objects:  49% (83/169)\u001b[K\rremote: Counting objects:  50% (85/169)\u001b[K\rremote: Counting objects:  51% (87/169)\u001b[K\rremote: Counting objects:  52% (88/169)\u001b[K\rremote: Counting objects:  53% (90/169)\u001b[K\rremote: Counting objects:  54% (92/169)\u001b[K\rremote: Counting objects:  55% (93/169)\u001b[K\rremote: Counting objects:  56% (95/169)\u001b[K\rremote: Counting objects:  57% (97/169)\u001b[K\rremote: Counting objects:  58% (99/169)\u001b[K\rremote: Counting objects:  59% (100/169)\u001b[K\rremote: Counting objects:  60% (102/169)\u001b[K\rremote: Counting objects:  61% (104/169)\u001b[K\rremote: Counting objects:  62% (105/169)\u001b[K\rremote: Counting objects:  63% (107/169)\u001b[K\rremote: Counting objects:  64% (109/169)\u001b[K\rremote: Counting objects:  65% (110/169)\u001b[K\rremote: Counting objects:  66% (112/169)\u001b[K\rremote: Counting objects:  67% (114/169)\u001b[K\rremote: Counting objects:  68% (115/169)\u001b[K\rremote: Counting objects:  69% (117/169)\u001b[K\rremote: Counting objects:  70% (119/169)\u001b[K\rremote: Counting objects:  71% (120/169)\u001b[K\rremote: Counting objects:  72% (122/169)\u001b[K\rremote: Counting objects:  73% (124/169)\u001b[K\rremote: Counting objects:  74% (126/169)\u001b[K\rremote: Counting objects:  75% (127/169)\u001b[K\rremote: Counting objects:  76% (129/169)\u001b[K\rremote: Counting objects:  77% (131/169)\u001b[K\rremote: Counting objects:  78% (132/169)\u001b[K\rremote: Counting objects:  79% (134/169)\u001b[K\rremote: Counting objects:  80% (136/169)\u001b[K\rremote: Counting objects:  81% (137/169)\u001b[K\rremote: Counting objects:  82% (139/169)\u001b[K\rremote: Counting objects:  83% (141/169)\u001b[K\rremote: Counting objects:  84% (142/169)\u001b[K\rremote: Counting objects:  85% (144/169)\u001b[K\rremote: Counting objects:  86% (146/169)\u001b[K\rremote: Counting objects:  87% (148/169)\u001b[K\rremote: Counting objects:  88% (149/169)\u001b[K\rremote: Counting objects:  89% (151/169)\u001b[K\rremote: Counting objects:  90% (153/169)\u001b[K\rremote: Counting objects:  91% (154/169)\u001b[K\rremote: Counting objects:  92% (156/169)\u001b[K\rremote: Counting objects:  93% (158/169)\u001b[K\rremote: Counting objects:  94% (159/169)\u001b[K\rremote: Counting objects:  95% (161/169)\u001b[K\rremote: Counting objects:  96% (163/169)\u001b[K\rremote: Counting objects:  97% (164/169)\u001b[K\rremote: Counting objects:  98% (166/169)\u001b[K\rremote: Counting objects:  99% (168/169)\u001b[K\rremote: Counting objects: 100% (169/169)\u001b[K\rremote: Counting objects: 100% (169/169), done.\u001b[K\n",
            "remote: Compressing objects:   1% (1/74)\u001b[K\rremote: Compressing objects:   2% (2/74)\u001b[K\rremote: Compressing objects:   4% (3/74)\u001b[K\rremote: Compressing objects:   5% (4/74)\u001b[K\rremote: Compressing objects:   6% (5/74)\u001b[K\rremote: Compressing objects:   8% (6/74)\u001b[K\rremote: Compressing objects:   9% (7/74)\u001b[K\rremote: Compressing objects:  10% (8/74)\u001b[K\rremote: Compressing objects:  12% (9/74)\u001b[K\rremote: Compressing objects:  13% (10/74)\u001b[K\rremote: Compressing objects:  14% (11/74)\u001b[K\rremote: Compressing objects:  16% (12/74)\u001b[K\rremote: Compressing objects:  17% (13/74)\u001b[K\rremote: Compressing objects:  18% (14/74)\u001b[K\rremote: Compressing objects:  20% (15/74)\u001b[K\rremote: Compressing objects:  21% (16/74)\u001b[K\rremote: Compressing objects:  22% (17/74)\u001b[K\rremote: Compressing objects:  24% (18/74)\u001b[K\rremote: Compressing objects:  25% (19/74)\u001b[K\rremote: Compressing objects:  27% (20/74)\u001b[K\rremote: Compressing objects:  28% (21/74)\u001b[K\rremote: Compressing objects:  29% (22/74)\u001b[K\rremote: Compressing objects:  31% (23/74)\u001b[K\rremote: Compressing objects:  32% (24/74)\u001b[K\rremote: Compressing objects:  33% (25/74)\u001b[K\rremote: Compressing objects:  35% (26/74)\u001b[K\rremote: Compressing objects:  36% (27/74)\u001b[K\rremote: Compressing objects:  37% (28/74)\u001b[K\rremote: Compressing objects:  39% (29/74)\u001b[K\rremote: Compressing objects:  40% (30/74)\u001b[K\rremote: Compressing objects:  41% (31/74)\u001b[K\rremote: Compressing objects:  43% (32/74)\u001b[K\rremote: Compressing objects:  44% (33/74)\u001b[K\rremote: Compressing objects:  45% (34/74)\u001b[K\rremote: Compressing objects:  47% (35/74)\u001b[K\rremote: Compressing objects:  48% (36/74)\u001b[K\rremote: Compressing objects:  50% (37/74)\u001b[K\rremote: Compressing objects:  51% (38/74)\u001b[K\rremote: Compressing objects:  52% (39/74)\u001b[K\rremote: Compressing objects:  54% (40/74)\u001b[K\rremote: Compressing objects:  55% (41/74)\u001b[K\rremote: Compressing objects:  56% (42/74)\u001b[K\rremote: Compressing objects:  58% (43/74)\u001b[K\rremote: Compressing objects:  59% (44/74)\u001b[K\rremote: Compressing objects:  60% (45/74)\u001b[K\rremote: Compressing objects:  62% (46/74)\u001b[K\rremote: Compressing objects:  63% (47/74)\u001b[K\rremote: Compressing objects:  64% (48/74)\u001b[K\rremote: Compressing objects:  66% (49/74)\u001b[K\rremote: Compressing objects:  67% (50/74)\u001b[K\rremote: Compressing objects:  68% (51/74)\u001b[K\rremote: Compressing objects:  70% (52/74)\u001b[K\rremote: Compressing objects:  71% (53/74)\u001b[K\rremote: Compressing objects:  72% (54/74)\u001b[K\rremote: Compressing objects:  74% (55/74)\u001b[K\rremote: Compressing objects:  75% (56/74)\u001b[K\rremote: Compressing objects:  77% (57/74)\u001b[K\rremote: Compressing objects:  78% (58/74)\u001b[K\rremote: Compressing objects:  79% (59/74)\u001b[K\rremote: Compressing objects:  81% (60/74)\u001b[K\rremote: Compressing objects:  82% (61/74)\u001b[K\rremote: Compressing objects:  83% (62/74)\u001b[K\rremote: Compressing objects:  85% (63/74)\u001b[K\rremote: Compressing objects:  86% (64/74)\u001b[K\rremote: Compressing objects:  87% (65/74)\u001b[K\rremote: Compressing objects:  89% (66/74)\u001b[K\rremote: Compressing objects:  90% (67/74)\u001b[K\rremote: Compressing objects:  91% (68/74)\u001b[K\rremote: Compressing objects:  93% (69/74)\u001b[K\rremote: Compressing objects:  94% (70/74)\u001b[K\rremote: Compressing objects:  95% (71/74)\u001b[K\rremote: Compressing objects:  97% (72/74)\u001b[K\rremote: Compressing objects:  98% (73/74)\u001b[K\rremote: Compressing objects: 100% (74/74)\u001b[K\rremote: Compressing objects: 100% (74/74), done.\u001b[K\n",
            "Receiving objects:   0% (1/26360)   \rReceiving objects:   1% (264/26360)   \rReceiving objects:   2% (528/26360)   \rReceiving objects:   3% (791/26360)   \rReceiving objects:   4% (1055/26360)   \rReceiving objects:   5% (1318/26360)   \rReceiving objects:   6% (1582/26360)   \rReceiving objects:   7% (1846/26360)   \rReceiving objects:   8% (2109/26360)   \rReceiving objects:   9% (2373/26360)   \rReceiving objects:  10% (2636/26360)   \rReceiving objects:  11% (2900/26360)   \rReceiving objects:  12% (3164/26360)   \rReceiving objects:  13% (3427/26360)   \rReceiving objects:  14% (3691/26360)   \rReceiving objects:  15% (3954/26360)   \rReceiving objects:  16% (4218/26360)   \rReceiving objects:  17% (4482/26360)   \rReceiving objects:  18% (4745/26360), 2.18 MiB | 4.34 MiB/s   \rReceiving objects:  19% (5009/26360), 2.18 MiB | 4.34 MiB/s   \rReceiving objects:  20% (5272/26360), 2.18 MiB | 4.34 MiB/s   \rReceiving objects:  21% (5536/26360), 2.18 MiB | 4.34 MiB/s   \rReceiving objects:  22% (5800/26360), 2.18 MiB | 4.34 MiB/s   \rReceiving objects:  23% (6063/26360), 2.18 MiB | 4.34 MiB/s   \rReceiving objects:  24% (6327/26360), 2.18 MiB | 4.34 MiB/s   \rReceiving objects:  25% (6590/26360), 2.18 MiB | 4.34 MiB/s   \rReceiving objects:  26% (6854/26360), 2.18 MiB | 4.34 MiB/s   \rReceiving objects:  27% (7118/26360), 2.18 MiB | 4.34 MiB/s   \rReceiving objects:  28% (7381/26360), 2.18 MiB | 4.34 MiB/s   \rReceiving objects:  29% (7645/26360), 2.18 MiB | 4.34 MiB/s   \rReceiving objects:  30% (7908/26360), 2.18 MiB | 4.34 MiB/s   \rReceiving objects:  31% (8172/26360), 2.18 MiB | 4.34 MiB/s   \rReceiving objects:  32% (8436/26360), 2.18 MiB | 4.34 MiB/s   \rReceiving objects:  33% (8699/26360), 2.18 MiB | 4.34 MiB/s   \rReceiving objects:  34% (8963/26360), 2.18 MiB | 4.34 MiB/s   \rReceiving objects:  35% (9226/26360), 2.18 MiB | 4.34 MiB/s   \rReceiving objects:  36% (9490/26360), 2.18 MiB | 4.34 MiB/s   \rReceiving objects:  37% (9754/26360), 2.18 MiB | 4.34 MiB/s   \rReceiving objects:  38% (10017/26360), 2.18 MiB | 4.34 MiB/s   \rReceiving objects:  39% (10281/26360), 2.18 MiB | 4.34 MiB/s   \rReceiving objects:  40% (10544/26360), 2.18 MiB | 4.34 MiB/s   \rReceiving objects:  41% (10808/26360), 2.18 MiB | 4.34 MiB/s   \rReceiving objects:  42% (11072/26360), 2.18 MiB | 4.34 MiB/s   \rReceiving objects:  43% (11335/26360), 2.18 MiB | 4.34 MiB/s   \rReceiving objects:  44% (11599/26360), 2.18 MiB | 4.34 MiB/s   \rReceiving objects:  45% (11862/26360), 2.18 MiB | 4.34 MiB/s   \rReceiving objects:  46% (12126/26360), 2.18 MiB | 4.34 MiB/s   \rReceiving objects:  47% (12390/26360), 2.18 MiB | 4.34 MiB/s   \rReceiving objects:  48% (12653/26360), 2.18 MiB | 4.34 MiB/s   \rReceiving objects:  49% (12917/26360), 2.18 MiB | 4.34 MiB/s   \rReceiving objects:  50% (13180/26360), 2.18 MiB | 4.34 MiB/s   \rReceiving objects:  51% (13444/26360), 2.18 MiB | 4.34 MiB/s   \rReceiving objects:  52% (13708/26360), 2.18 MiB | 4.34 MiB/s   \rReceiving objects:  53% (13971/26360), 2.18 MiB | 4.34 MiB/s   \rReceiving objects:  54% (14235/26360), 2.18 MiB | 4.34 MiB/s   \rReceiving objects:  55% (14498/26360), 2.18 MiB | 4.34 MiB/s   \rReceiving objects:  56% (14762/26360), 2.18 MiB | 4.34 MiB/s   \rReceiving objects:  57% (15026/26360), 2.18 MiB | 4.34 MiB/s   \rReceiving objects:  58% (15289/26360), 2.18 MiB | 4.34 MiB/s   \rReceiving objects:  59% (15553/26360), 2.18 MiB | 4.34 MiB/s   \rReceiving objects:  60% (15816/26360), 2.18 MiB | 4.34 MiB/s   \rReceiving objects:  61% (16080/26360), 2.18 MiB | 4.34 MiB/s   \rReceiving objects:  62% (16344/26360), 2.18 MiB | 4.34 MiB/s   \rReceiving objects:  63% (16607/26360), 2.18 MiB | 4.34 MiB/s   \rReceiving objects:  64% (16871/26360), 2.18 MiB | 4.34 MiB/s   \rReceiving objects:  65% (17134/26360), 2.18 MiB | 4.34 MiB/s   \rReceiving objects:  66% (17398/26360), 2.18 MiB | 4.34 MiB/s   \rReceiving objects:  67% (17662/26360), 2.18 MiB | 4.34 MiB/s   \rReceiving objects:  68% (17925/26360), 2.18 MiB | 4.34 MiB/s   \rReceiving objects:  69% (18189/26360), 2.18 MiB | 4.34 MiB/s   \rReceiving objects:  70% (18452/26360), 2.18 MiB | 4.34 MiB/s   \rReceiving objects:  71% (18716/26360), 2.18 MiB | 4.34 MiB/s   \rReceiving objects:  72% (18980/26360), 2.18 MiB | 4.34 MiB/s   \rReceiving objects:  73% (19243/26360), 2.18 MiB | 4.34 MiB/s   \rReceiving objects:  74% (19507/26360), 2.18 MiB | 4.34 MiB/s   \rReceiving objects:  75% (19770/26360), 2.18 MiB | 4.34 MiB/s   \rReceiving objects:  76% (20034/26360), 2.18 MiB | 4.34 MiB/s   \rReceiving objects:  77% (20298/26360), 2.18 MiB | 4.34 MiB/s   \rReceiving objects:  78% (20561/26360), 2.18 MiB | 4.34 MiB/s   \rReceiving objects:  79% (20825/26360), 2.18 MiB | 4.34 MiB/s   \rReceiving objects:  80% (21088/26360), 2.18 MiB | 4.34 MiB/s   \rReceiving objects:  81% (21352/26360), 2.18 MiB | 4.34 MiB/s   \rReceiving objects:  82% (21616/26360), 2.18 MiB | 4.34 MiB/s   \rReceiving objects:  83% (21879/26360), 2.18 MiB | 4.34 MiB/s   \rReceiving objects:  84% (22143/26360), 2.18 MiB | 4.34 MiB/s   \rReceiving objects:  85% (22406/26360), 2.18 MiB | 4.34 MiB/s   \rReceiving objects:  86% (22670/26360), 2.18 MiB | 4.34 MiB/s   \rReceiving objects:  87% (22934/26360), 2.18 MiB | 4.34 MiB/s   \rReceiving objects:  88% (23197/26360), 2.18 MiB | 4.34 MiB/s   \rReceiving objects:  88% (23201/26360), 2.18 MiB | 4.34 MiB/s   \rReceiving objects:  89% (23461/26360), 14.80 MiB | 14.77 MiB/s   \rReceiving objects:  90% (23724/26360), 14.80 MiB | 14.77 MiB/s   \rReceiving objects:  91% (23988/26360), 14.80 MiB | 14.77 MiB/s   \rReceiving objects:  92% (24252/26360), 14.80 MiB | 14.77 MiB/s   \rReceiving objects:  93% (24515/26360), 14.80 MiB | 14.77 MiB/s   \rReceiving objects:  94% (24779/26360), 14.80 MiB | 14.77 MiB/s   \rReceiving objects:  95% (25042/26360), 14.80 MiB | 14.77 MiB/s   \rReceiving objects:  96% (25306/26360), 14.80 MiB | 14.77 MiB/s   \rReceiving objects:  97% (25570/26360), 14.80 MiB | 14.77 MiB/s   \rReceiving objects:  98% (25833/26360), 14.80 MiB | 14.77 MiB/s   \rReceiving objects:  99% (26097/26360), 14.80 MiB | 14.77 MiB/s   \rremote: Total 26360 (delta 76), reused 137 (delta 65), pack-reused 26191\u001b[K\n",
            "Receiving objects: 100% (26360/26360), 14.80 MiB | 14.77 MiB/s   \rReceiving objects: 100% (26360/26360), 15.93 MiB | 15.27 MiB/s, done.\n",
            "Resolving deltas:   0% (0/18341)   \rResolving deltas:   1% (184/18341)   \rResolving deltas:   2% (382/18341)   \rResolving deltas:   3% (574/18341)   \rResolving deltas:   4% (735/18341)   \rResolving deltas:   5% (918/18341)   \rResolving deltas:   7% (1357/18341)   \rResolving deltas:   8% (1485/18341)   \rResolving deltas:   9% (1652/18341)   \rResolving deltas:  10% (1846/18341)   \rResolving deltas:  11% (2104/18341)   \rResolving deltas:  12% (2201/18341)   \rResolving deltas:  13% (2410/18341)   \rResolving deltas:  14% (2570/18341)   \rResolving deltas:  15% (2801/18341)   \rResolving deltas:  16% (2939/18341)   \rResolving deltas:  18% (3316/18341)   \rResolving deltas:  19% (3515/18341)   \rResolving deltas:  20% (3683/18341)   \rResolving deltas:  21% (3863/18341)   \rResolving deltas:  22% (4043/18341)   \rResolving deltas:  23% (4280/18341)   \rResolving deltas:  24% (4414/18341)   \rResolving deltas:  25% (4589/18341)   \rResolving deltas:  26% (4770/18341)   \rResolving deltas:  27% (4960/18341)   \rResolving deltas:  28% (5145/18341)   \rResolving deltas:  29% (5371/18341)   \rResolving deltas:  30% (5507/18341)   \rResolving deltas:  31% (5703/18341)   \rResolving deltas:  32% (5909/18341)   \rResolving deltas:  33% (6096/18341)   \rResolving deltas:  34% (6250/18341)   \rResolving deltas:  36% (6636/18341)   \rResolving deltas:  37% (6821/18341)   \rResolving deltas:  38% (7003/18341)   \rResolving deltas:  39% (7174/18341)   \rResolving deltas:  40% (7349/18341)   \rResolving deltas:  41% (7524/18341)   \rResolving deltas:  42% (7756/18341)   \rResolving deltas:  43% (7898/18341)   \rResolving deltas:  44% (8072/18341)   \rResolving deltas:  45% (8312/18341)   \rResolving deltas:  46% (8441/18341)   \rResolving deltas:  47% (8685/18341)   \rResolving deltas:  48% (8840/18341)   \rResolving deltas:  49% (9032/18341)   \rResolving deltas:  51% (9392/18341)   \rResolving deltas:  52% (9543/18341)   \rResolving deltas:  53% (9727/18341)   \rResolving deltas:  54% (9963/18341)   \rResolving deltas:  55% (10104/18341)   \rResolving deltas:  56% (10286/18341)   \rResolving deltas:  57% (10478/18341)   \rResolving deltas:  58% (10675/18341)   \rResolving deltas:  59% (10827/18341)   \rResolving deltas:  60% (11047/18341)   \rResolving deltas:  61% (11191/18341)   \rResolving deltas:  62% (11424/18341)   \rResolving deltas:  63% (11600/18341)   \rResolving deltas:  64% (11754/18341)   \rResolving deltas:  65% (11967/18341)   \rResolving deltas:  67% (12393/18341)   \rResolving deltas:  68% (12473/18341)   \rResolving deltas:  69% (12680/18341)   \rResolving deltas:  70% (12842/18341)   \rResolving deltas:  71% (13056/18341)   \rResolving deltas:  72% (13216/18341)   \rResolving deltas:  73% (13402/18341)   \rResolving deltas:  74% (13573/18341)   \rResolving deltas:  75% (13795/18341)   \rResolving deltas:  76% (14024/18341)   \rResolving deltas:  77% (14264/18341)   \rResolving deltas:  78% (14321/18341)   \rResolving deltas:  79% (14493/18341)   \rResolving deltas:  80% (14819/18341)   \rResolving deltas:  80% (14823/18341)   \rResolving deltas:  81% (14953/18341)   \rResolving deltas:  82% (15050/18341)   \rResolving deltas:  83% (15247/18341)   \rResolving deltas:  84% (15421/18341)   \rResolving deltas:  85% (15594/18341)   \rResolving deltas:  86% (15825/18341)   \rResolving deltas:  87% (15957/18341)   \rResolving deltas:  88% (16144/18341)   \rResolving deltas:  89% (16326/18341)   \rResolving deltas:  90% (16508/18341)   \rResolving deltas:  91% (16691/18341)   \rResolving deltas:  92% (16881/18341)   \rResolving deltas:  93% (17144/18341)   \rResolving deltas:  94% (17242/18341)   \rResolving deltas:  95% (17439/18341)   \rResolving deltas:  96% (17696/18341)   \rResolving deltas:  97% (17816/18341)   \rResolving deltas:  98% (17985/18341)   \rResolving deltas:  99% (18158/18341)   \rResolving deltas: 100% (18341/18341)   \rResolving deltas: 100% (18341/18341), done.\n",
            "Note: checking out 'a3085020ed0d81d4903c50967687192e3101e770'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by performing another checkout.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -b with the checkout command again. Example:\n",
            "\n",
            "  git checkout -b <new-branch-name>\n",
            "\n",
            "HEAD is now at a3085020 Added repetition penalty to PPLM example (#2436)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRARhN-oVSTN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 826
        },
        "outputId": "406e89f5-e6ad-4009-daa9-591eae02e1cc"
      },
      "source": [
        "!pip install ./transformers\n",
        "!pip install tensorboardX"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing ./transformers\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0) (1.18.4)\n",
            "Collecting tokenizers==0.0.11\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/36/7af38d572c935f8e0462ec7b4f7a46d73a2b3b1a938f50a5e8132d5b2dc5/tokenizers-0.0.11-cp36-cp36m-manylinux1_x86_64.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 68kB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0) (1.13.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0) (2019.12.20)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/88/49e772d686088e1278766ad68a463513642a2a877487decbd691dec02955/sentencepiece-0.1.90-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 50.8MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 48.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.3.0) (0.9.5)\n",
            "Requirement already satisfied: botocore<1.17.0,>=1.16.4 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.3.0) (1.16.4)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.3.0) (0.3.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.3.0) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.3.0) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.3.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.3.0) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.3.0) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.3.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.3.0) (0.14.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.4->boto3->transformers==2.3.0) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.4->boto3->transformers==2.3.0) (0.15.2)\n",
            "Building wheels for collected packages: transformers, sacremoses\n",
            "  Building wheel for transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-2.3.0-cp36-none-any.whl size=458557 sha256=af233fce0381447e318d6cbd7d504ec11766031d783ded11e95f73d115b7c2ac\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-6h5cj0jq/wheels/23/19/dd/2561a4e47240cf6b307729d58e56f8077dd0c698f5992216cf\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=f9de05a55669878c6f2c60e9d56ce832ebd51db476d68329568b1855119521d3\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built transformers sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.90 tokenizers-0.0.11 transformers-2.3.0\n",
            "Collecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/f1/5843425495765c8c2dd0784a851a93ef204d314fc87bcc2bbb9f662a3ad1/tensorboardX-2.0-py2.py3-none-any.whl (195kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 8.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.18.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardX) (46.1.3)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYlsRklJVWFS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "8a0353af-975e-4bbc-c5a0-5e4c4a4a85da"
      },
      "source": [
        "!mkdir dataset \\\n",
        "&& cd dataset \\\n",
        "&& wget https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json \\\n",
        "&& wget https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-13 21:31:37--  https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json\n",
            "Resolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.109.153, 185.199.111.153, 185.199.108.153, ...\n",
            "Connecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.109.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 42123633 (40M) [application/json]\n",
            "Saving to: ‘train-v2.0.json’\n",
            "\n",
            "\rtrain-v2.0.json       0%[                    ]       0  --.-KB/s               \rtrain-v2.0.json      33%[=====>              ]  13.56M  67.7MB/s               \rtrain-v2.0.json     100%[===================>]  40.17M   138MB/s    in 0.3s    \n",
            "\n",
            "2020-05-13 21:31:38 (138 MB/s) - ‘train-v2.0.json’ saved [42123633/42123633]\n",
            "\n",
            "--2020-05-13 21:31:38--  https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json\n",
            "Resolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.109.153, 185.199.111.153, 185.199.108.153, ...\n",
            "Connecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.109.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4370528 (4.2M) [application/json]\n",
            "Saving to: ‘dev-v2.0.json’\n",
            "\n",
            "dev-v2.0.json       100%[===================>]   4.17M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-05-13 21:31:39 (37.3 MB/s) - ‘dev-v2.0.json’ saved [4370528/4370528]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idBXu4FrVkgU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "f35f76c5-cb87-4325-d685-a6f8ba2ed468"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import time\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "from transformers import (\n",
        "    AlbertConfig,\n",
        "    AlbertForQuestionAnswering,\n",
        "    AlbertTokenizer,\n",
        "    squad_convert_examples_to_features\n",
        ")\n",
        "\n",
        "from transformers.data.processors.squad import SquadResult, SquadV2Processor, SquadExample\n",
        "\n",
        "from transformers.data.metrics.squad_metrics import compute_predictions_logits\n",
        "\n",
        "# READER NOTE: Set this flag to use own model, or use pretrained model in the Hugging Face repository\n",
        "use_own_model = True\n",
        "\n",
        "if use_own_model:\n",
        "  model_name_or_path = \"/content/albert_v2_base.tar.gz\"\n",
        "else:\n",
        "  model_name_or_path = \"ktrapeznikov/albert-xlarge-v2-squad-v2\"\n",
        "\n",
        "output_dir = \"\"\n",
        "\n",
        "# Config\n",
        "n_best_size = 1\n",
        "max_answer_length = 30\n",
        "do_lower_case = True\n",
        "null_score_diff_threshold = 0.0\n",
        "\n",
        "def to_list(tensor):\n",
        "    return tensor.detach().cpu().tolist()\n",
        "\n",
        "# Setup model\n",
        "config_class, model_class, tokenizer_class = (\n",
        "    AlbertConfig, AlbertForQuestionAnswering, AlbertTokenizer)\n",
        "config = config_class.from_pretrained('/content/albert_v2_base.tar.gz')\n",
        "tokenizer = tokenizer_class.from_pretrained(\n",
        "    model_name_or_path, do_lower_case=True)\n",
        "model = model_class.from_pretrained(model_name_or_path, config=config)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "processor = SquadV2Processor()\n",
        "\n",
        "def run_prediction(question_texts, context_text):\n",
        "    \"\"\"Setup function to compute predictions\"\"\"\n",
        "    examples = []\n",
        "\n",
        "    for i, question_text in enumerate(question_texts):\n",
        "        example = SquadExample(\n",
        "            qas_id=str(i),\n",
        "            question_text=question_text,\n",
        "            context_text=context_text,\n",
        "            answer_text=None,\n",
        "            start_position_character=None,\n",
        "            title=\"Predict\",\n",
        "            is_impossible=False,\n",
        "            answers=None,\n",
        "        )\n",
        "\n",
        "        examples.append(example)\n",
        "\n",
        "    features, dataset = squad_convert_examples_to_features(\n",
        "        examples=examples,\n",
        "        tokenizer=tokenizer,\n",
        "        max_seq_length=384,\n",
        "        doc_stride=128,\n",
        "        max_query_length=64,\n",
        "        is_training=False,\n",
        "        return_dataset=\"pt\",\n",
        "        threads=1,\n",
        "    )\n",
        "\n",
        "    eval_sampler = SequentialSampler(dataset)\n",
        "    eval_dataloader = DataLoader(dataset, sampler=eval_sampler, batch_size=10)\n",
        "\n",
        "    all_results = []\n",
        "\n",
        "    for batch in eval_dataloader:\n",
        "        model.eval()\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            inputs = {\n",
        "                \"input_ids\": batch[0],\n",
        "                \"attention_mask\": batch[1],\n",
        "                \"token_type_ids\": batch[2],\n",
        "            }\n",
        "\n",
        "            example_indices = batch[3]\n",
        "\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "            for i, example_index in enumerate(example_indices):\n",
        "                eval_feature = features[example_index.item()]\n",
        "                unique_id = int(eval_feature.unique_id)\n",
        "\n",
        "                output = [to_list(output[i]) for output in outputs]\n",
        "\n",
        "                start_logits, end_logits = output\n",
        "                result = SquadResult(unique_id, start_logits, end_logits)\n",
        "                all_results.append(result)\n",
        "\n",
        "    output_prediction_file = \"predictions.json\"\n",
        "    output_nbest_file = \"nbest_predictions.json\"\n",
        "    output_null_log_odds_file = \"null_predictions.json\"\n",
        "\n",
        "    predictions = compute_predictions_logits(\n",
        "        examples,\n",
        "        features,\n",
        "        all_results,\n",
        "        n_best_size,\n",
        "        max_answer_length,\n",
        "        do_lower_case,\n",
        "        output_prediction_file,\n",
        "        output_nbest_file,\n",
        "        output_null_log_odds_file,\n",
        "        False,  # verbose_logging\n",
        "        True,  # version_2_with_negative\n",
        "        null_score_diff_threshold,\n",
        "        tokenizer,\n",
        "    )\n",
        "\n",
        "    return predictions"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnicodeDecodeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-9d5e87450a5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m config_class, model_class, tokenizer_class = (\n\u001b[1;32m     38\u001b[0m     AlbertConfig, AlbertForQuestionAnswering, AlbertTokenizer)\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/albert_v2_base.tar.gz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m tokenizer = tokenizer_class.from_pretrained(\n\u001b[1;32m     41\u001b[0m     model_name_or_path, do_lower_case=True)\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m             )\n\u001b[1;32m    181\u001b[0m             \u001b[0;31m# Load config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_json_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolved_config_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mEnvironmentError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mfrom_json_file\u001b[0;34m(cls, json_file)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;34m\"\"\"Constructs a `Config` from a json file of parameters.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m         \u001b[0mdict_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdict_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsumed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m         \u001b[0;31m# keep undecoded input until the next call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconsumed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x8b in position 1: invalid start byte"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHSXCieiVoiv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "2fa0c76b-1c8a-405c-f205-2ad664473150"
      },
      "source": [
        "context = [\"\"]\n",
        "questions = [\"\"]\n",
        "\n",
        "# Run method\n",
        "predictions = run_prediction(questions, context)\n",
        "\n",
        "# Print results\n",
        "for key in predictions.keys():\n",
        "  print(predictions[key])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "convert squad examples to features: 100%|██████████| 1/1 [00:00<00:00, 129.37it/s]\n",
            "add example index and unique id: 100%|██████████| 1/1 [00:00<00:00, 2176.60it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Junior Machine Learning Engineer\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kc5gtuxLVtzz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}